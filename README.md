üö¶ Controle de Sem√°foro Inteligente

Projeto de Machine Learning usando **Aprendizado por Refor√ßo (Q-Learning)** para otimizar o controle de sem√°foro com base no fluxo de ve√≠culos. O objetivo √© reduzir o tempo m√©dio de espera dos carros e melhorar o fluxo em uma interse√ß√£o simples.


üìå Objetivo
Treinar um agente que aprenda a alternar os sinais de tr√¢nsito com base no n√∫mero de ve√≠culos em cada via, utilizando **Q-Learning** para maximizar o n√∫mero de carros que passam e minimizar o tempo de espera.


üõ†Ô∏è Tecnologias e Bibliotecas Utilizadas

- Python 3.x  
- NumPy  
- Matplotlib  
- Pandas (opcional)



üìò Algoritmo Utilizado

**Q-Learning**

> F√≥rmula de atualiza√ß√£o:
```python
Q[s][a] = Q[s][a] + alpha * (reward + gamma * max(Q[new_state]) - Q[s][a])

Œ± (alpha): taxa de aprendizado

Œ≥ (gamma): fator de desconto

Œµ (epsilon): taxa de explora√ß√£o (Œµ-greedy)
```

üß™ Como Executar o Projeto

# Clone o reposit√≥rio
git clone https://github.com/WGlyma/Controle-de-semafaro--01633979---Wilamy-gabriel-.git
cd Controle-de-semafaro--01633979---Wilamy-gabriel-

# Instale os requisitos
pip install -r requirements.txt

# Execute o treinamento
python main.py


üìä Resultados Obtidos

‚úÖ Redu√ß√£o do tempo m√©dio de espera

‚úÖ Aumento no n√∫mero de ve√≠culos processados

‚úÖ Evolu√ß√£o da recompensa total ao longo dos epis√≥dios


üß† Dificuldades Encontradas
Definir uma fun√ß√£o de recompensa que equilibre bem os fluxos

Ajustar corretamente o valor de epsilon para balancear explora√ß√£o e explora√ß√£o

Modelar estados sem que fiquem grandes demais (explos√£o de estados)
üìà Exemplo de gr√°fico (substitua pelo seu print real)


‚úÖ Coment√°rios Finais
Este projeto demonstrou como t√©cnicas de aprendizado por refor√ßo podem ser aplicadas a problemas reais. Mesmo em uma simula√ß√£o simples, foi poss√≠vel observar o aprendizado do agente e os impactos positivos no desempenho do sem√°foro.
